% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knn.R
\name{fastknnCV}
\alias{fastknnCV}
\title{Cross-Validation for fastknn}
\usage{
fastknnCV(x, y, k = 3:15, method = "dist", normalize = NULL, folds = 5,
  eval.metric = "overall_error", nthread = 1)
}
\arguments{
\item{x}{input matrix of dimension \code{nobs x nvars}.}

\item{y}{factor array wtih class labels for the \code{x} rows.}

\item{k}{sequence of possible k values to be evaluated (default is [3:15]).}

\item{method}{the probability estimator as in \code{\link{fastknn}}.}

\item{normalize}{variable scaler as in \code{\link{fastknn}}.}

\item{folds}{number of folds (default is 5) or an array with fold ids between 
1 and \code{n} identifying what fold each observation is in. The smallest 
value allowable is \code{nfolds=3}. The fold assigment given by 
\code{fastknnCV} does stratified sampling.}

\item{eval.metric}{classification loss measure to use in cross-validation. 
See \code{\link{classLoss}} for more details.}

\item{nthread}{the number of CPU threads to use (default is 1).}
}
\value{
\code{list} with cross-validation results:
\itemize{
 \item \code{best_eval}: the best loss measure found in the 
 cross-validation procedure.
 \item \code{best_k}: the best k value found in the cross-validation procedure.
 \item \code{cv_table}: \code{data.frame} with the test performances for each k 
 on each data fold. 
}
}
\description{
Does n-fold cross-validation for \code{fastknn} to find the best k parameter.
}
\examples{
\dontrun{
library("mlbench")
library("caTools")
library("fastknn")

data("Ionosphere")

x <- data.matrix(subset(Ionosphere, select = -Class))
y <- Ionosphere$Class

set.seed(1024)
tr.idx <- which(sample.split(Y = y, SplitRatio = 0.7))
x.tr <- x[tr.idx,]
x.te <- x[-tr.idx,]
y.tr <- y[tr.idx]
y.te <- y[-tr.idx]

set.seed(2048)
cv.out <- fastknnCV(x = x.tr, y = y.tr, k = c(5,10,15,20), eval.metric="logloss")

cv.out$cv_table
}
}
\author{
David Pinto.
}
\seealso{
\code{\link{classLoss}}
}

