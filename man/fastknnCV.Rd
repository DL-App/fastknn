% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knn.R
\name{fastknnCV}
\alias{fastknnCV}
\title{Cross-Validation for fastknn}
\usage{
fastknnCV(x, y, k = 3:15, method = "dist", folds = 5,
  eval.metric = "overall_error")
}
\arguments{
\item{x}{input matrix of dimension \code{nobs x nvars}.}

\item{y}{factor array wtih class labels for the \code{x} rows.}

\item{k}{sequence of possible k values to be evaluated (default is [3:15]).}

\item{method}{the probability estimator as in \code{fastknn}.}

\item{folds}{number of folds (default is 5) or an array with fold ids between 
1 and \code{n} identifying what fold each observation is in. The smallest 
value allowable is \code{nfolds=3}. The fold assigment given by 
\code{fastknnCV} does stratified sampling.}

\item{eval.metric}{classification loss measure to use in cross-validation. 
See \code{\link{classLoss}} for more details.}
}
\value{
\code{list} with cross-validation results:
\itemize{
 \item \code{best_eval}: the best loss measure found in the 
 cross-validation procedure.
 \item \code{best_k}: the best k value found in the cross-validation procedure.
 \item \code{cv_table}: \code{data.frame} with the test performances for each k 
 on each data fold. 
}
}
\description{
Does n-fold cross-validation for \code{fastknn} to find the best k parameter.
}

