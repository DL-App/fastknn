<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Feature Extraction with KNN &bull; fastknn</title><!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">fastknn</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/davpinto/fastknn">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Feature Extraction with KNN</h1>
                        <h4 class="author">David Pinto</h4>
            
          </div>

    
    
<div class="contents">
<p>The <strong>fastknn</strong> provides a function to do feature extraction using KNN. It generates <code>k * c</code> new features, where <code>c</code> is the number of class labels. The new features are computed from the distances between the observations and their <code>k</code> nearest neighbors inside each class, as follows:</p>
<ol style="list-style-type: decimal"><li>The first test feature contains the distances between each test instance and its nearest neighbor inside the first class.</li>
<li>The second test feature contains the sums of distances between each test instance and its 2 nearest neighbors inside the first class.</li>
<li>The third test feature contains the sums of distances between each test instance and its 3 nearest neighbors inside the first class.</li>
<li>And so on.</li>
</ol><p>This procedure repeats for each class label, generating <code>k * c</code> new features. Then, the new training features are generated using a n-fold CV approach, in order to avoid overfitting. Parallelization is available. You can specify the number of threads via <code>nthread</code> parameter.</p>
<p>The <strong>feature extraction</strong> technique proposed here is based on the ideas presented in the <a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/14335/1st-place-winner-solution-gilberto-titericz-stanislav-semenov">winner solution</a> of the <a href="https://www.kaggle.com/c/otto-group-product-classification-challenge">Otto Group Product Classification Challenge</a> on <strong>Kaggle</strong>.</p>
<p>The following example shows that the <strong>KNN features</strong> carry information about the original data that can not be extracted by a linear learner, like a GLM model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"mlbench"</span>)
<span class="kw">library</span>(<span class="st">"caTools"</span>)
<span class="kw">library</span>(<span class="st">"fastknn"</span>)
<span class="kw">library</span>(<span class="st">"glmnet"</span>)

#### Load data
<span class="kw">data</span>(<span class="st">"Ionosphere"</span>, <span class="dt">package =</span> <span class="st">"mlbench"</span>)
x &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(<span class="kw">subset</span>(Ionosphere, <span class="dt">select =</span> -Class))
y &lt;-<span class="st"> </span>Ionosphere$Class

#### Remove near zero variance columns
x &lt;-<span class="st"> </span>x[, -<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]

#### Split data
<span class="kw">set.seed</span>(<span class="dv">123</span>)
tr.idx &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">sample.split</span>(<span class="dt">Y =</span> y, <span class="dt">SplitRatio =</span> <span class="fl">0.7</span>))
x.tr &lt;-<span class="st"> </span>x[tr.idx,]
x.te &lt;-<span class="st"> </span>x[-tr.idx,]
y.tr &lt;-<span class="st"> </span>y[tr.idx]
y.te &lt;-<span class="st"> </span>y[-tr.idx]

#### GLM with original features
glm &lt;-<span class="st"> </span><span class="kw">glmnet</span>(<span class="dt">x =</span> x.tr, <span class="dt">y =</span> y.tr, <span class="dt">family =</span> <span class="st">"binomial"</span>, <span class="dt">lambda =</span> <span class="dv">0</span>)
yhat &lt;-<span class="st"> </span><span class="kw">drop</span>(<span class="kw">predict</span>(glm, x.te, <span class="dt">type =</span> <span class="st">"class"</span>))
yhat1 &lt;-<span class="st"> </span><span class="kw">factor</span>(yhat, <span class="dt">levels =</span> <span class="kw">levels</span>(y.tr))

#### Generate KNN features
<span class="kw">set.seed</span>(<span class="dv">123</span>)
new.data &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnExtract.html">knnExtract</a></span>(<span class="dt">xtr =</span> x.tr, <span class="dt">ytr =</span> y.tr, <span class="dt">xte =</span> x.te, <span class="dt">k =</span> <span class="dv">3</span>)

#### GLM with KNN features
glm &lt;-<span class="st"> </span><span class="kw">glmnet</span>(<span class="dt">x =</span> new.data$new.tr, <span class="dt">y =</span> y.tr, <span class="dt">family =</span> <span class="st">"binomial"</span>, <span class="dt">lambda =</span> <span class="dv">0</span>)
yhat &lt;-<span class="st"> </span><span class="kw">drop</span>(<span class="kw">predict</span>(glm, new.data$new.te, <span class="dt">type =</span> <span class="st">"class"</span>))
yhat2 &lt;-<span class="st"> </span><span class="kw">factor</span>(yhat, <span class="dt">levels =</span> <span class="kw">levels</span>(y.tr))

#### Performance
<span class="kw">sprintf</span>(<span class="st">"Accuracy with original features: %.2f"</span>, <span class="dv">100</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw"><a href="../reference/classLoss.html">classLoss</a></span>(<span class="dt">actual =</span> y.te, <span class="dt">predicted =</span> yhat1)))
<span class="kw">sprintf</span>(<span class="st">"Accuracy with KNN features: %.2f"</span>, <span class="dv">100</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw"><a href="../reference/classLoss.html">classLoss</a></span>(<span class="dt">actual =</span> y.te, <span class="dt">predicted =</span> yhat2)))</code></pre></div>
<pre><code>## [1] "Accuracy with original features: 83.81"</code></pre>
<pre><code>## [1] "Accuracy with KNN features: 95.24"</code></pre>
<p>For a more complete example, take a look at this <a href="https://www.kaggle.com/davidpinto/d/uciml/forest-cover-type-dataset/fastknn-show-to-glm-what-knn-see-0-96">Kaggle Kernel</a> showing how <code><a href="../reference/knnExtract.html">knnExtract()</a></code> peforms on a large dataset.</p>
<div id="understanding-the-knn-features" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#understanding-the-knn-features" class="anchor"> </a></body></html>Understanding the KNN Features</h2>
<p>KNN makes a nonlinear mapping of the original space and project it into a linear one, in which the classes are linearly separable.</p>
<p><strong>Mapping the <em>chess</em> dataset</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"caTools"</span>)
<span class="kw">library</span>(<span class="st">"fastknn"</span>)
<span class="kw">library</span>(<span class="st">"ggplot2"</span>)
<span class="kw">library</span>(<span class="st">"gridExtra"</span>)

## Load data
<span class="kw">data</span>(<span class="st">"chess"</span>)
x &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(chess$x)
y &lt;-<span class="st"> </span>chess$y

## Split data
<span class="kw">set.seed</span>(<span class="dv">123</span>)
tr.idx &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">sample.split</span>(<span class="dt">Y =</span> y, <span class="dt">SplitRatio =</span> <span class="fl">0.7</span>))
x.tr &lt;-<span class="st"> </span>x[tr.idx,]
x.te &lt;-<span class="st"> </span>x[-tr.idx,]
y.tr &lt;-<span class="st"> </span>y[tr.idx]
y.te &lt;-<span class="st"> </span>y[-tr.idx]

## Feature extraction with KNN
<span class="kw">set.seed</span>(<span class="dv">123</span>)
new.data &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnExtract.html">knnExtract</a></span>(x.tr, y.tr, x.te, <span class="dt">k =</span> <span class="dv">1</span>)

## Decision boundaries
g1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnDecision.html">knnDecision</a></span>(x.tr, y.tr, x.te, y.te, <span class="dt">k =</span> <span class="dv">10</span>) +
<span class="st">   </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Original Features"</span>)
g2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnDecision.html">knnDecision</a></span>(new.data$new.tr, y.tr, new.data$new.te, y.te, <span class="dt">k =</span> <span class="dv">10</span>) +
<span class="st">   </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"KNN Features"</span>)
<span class="kw">grid.arrange</span>(g1, g2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="knn-extraction_files/figure-html/unnamed-chunk-3-1.png" width="600" style="display: block; margin: auto;"></p>
<p><strong>Mapping the <em>spirals</em> dataset</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Load data
<span class="kw">data</span>(<span class="st">"spirals"</span>)
x &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(spirals$x)
y &lt;-<span class="st"> </span>spirals$y

## Split data
<span class="kw">set.seed</span>(<span class="dv">123</span>)
tr.idx &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">sample.split</span>(<span class="dt">Y =</span> y, <span class="dt">SplitRatio =</span> <span class="fl">0.7</span>))
x.tr &lt;-<span class="st"> </span>x[tr.idx,]
x.te &lt;-<span class="st"> </span>x[-tr.idx,]
y.tr &lt;-<span class="st"> </span>y[tr.idx]
y.te &lt;-<span class="st"> </span>y[-tr.idx]

## Feature extraction with KNN
<span class="kw">set.seed</span>(<span class="dv">123</span>)
new.data &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnExtract.html">knnExtract</a></span>(x.tr, y.tr, x.te, <span class="dt">k =</span> <span class="dv">1</span>)

## Decision boundaries
g1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnDecision.html">knnDecision</a></span>(x.tr, y.tr, x.te, y.te, <span class="dt">k =</span> <span class="dv">10</span>) +
<span class="st">   </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Original Features"</span>)
g2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/knnDecision.html">knnDecision</a></span>(new.data$new.tr, y.tr, new.data$new.te, y.te, <span class="dt">k =</span> <span class="dv">10</span>) +
<span class="st">   </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"KNN Features"</span>)
<span class="kw">grid.arrange</span>(g1, g2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="knn-extraction_files/figure-html/unnamed-chunk-4-1.png" width="600" style="display: block; margin: auto;"></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked"><li><a href="#understanding-the-knn-features">Understanding the KNN Features</a></li>
      </ul></div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by David Pinto.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer></div>

  </body></html>
